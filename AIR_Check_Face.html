<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Pose and Face Detection</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/pose-detection"></script>
    <style>
        body {
            font-family: Arial, sans-serif;
            text-align: center;
            background-color: #f0f0f0;
            margin: 0;
            padding: 0;
        }
        canvas, video {
            position: absolute;
            left: 50%;
            top: 50%;
            transform: translate(-50%, -50%);
        }
        #status {
            position: absolute;
            top: 10px;
            left: 50%;
            transform: translateX(-50%);
            background: rgba(255, 0, 0, 0.8);
            color: #fff;
            padding: 10px;
            border-radius: 5px;
            display: none;
        }
    </style>
</head>
<body>
    <h1>Pose and Face Detection</h1>
    <div id="status">Лицо не обнаружено</div>
    <video id="video" width="640" height="480" autoplay muted></video>
    <canvas id="output" width="640" height="480"></canvas>

    <script>
        const video = document.getElementById('video');
        const canvas = document.getElementById('output');
        const ctx = canvas.getContext('2d');
        const statusDiv = document.getElementById('status');

        let lastFaceDetected = false;

        async function setupCamera() {
            const stream = await navigator.mediaDevices.getUserMedia({
                video: { width: 640, height: 480 },
                audio: false
            });
            video.srcObject = stream;

            return new Promise((resolve) => {
                video.onloadedmetadata = () => {
                    resolve(video);
                };
            });
        }

        async function loadModelAndDetect() {
            // Load the MoveNet model
            const detector = await poseDetection.createDetector(poseDetection.SupportedModels.MoveNet);

            // Start detecting poses
            async function detectPose() {
                ctx.clearRect(0, 0, canvas.width, canvas.height);

                // Draw the video on the canvas
                ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

                // Detect poses
                const poses = await detector.estimatePoses(video);

                // Check if a face or body is detected
                if (poses.length > 0) {
                    lastFaceDetected = true;
                    statusDiv.style.display = 'none';

                    poses.forEach(pose => {
                        // Draw keypoints
                        pose.keypoints.forEach(({ x, y, score }) => {
                            if (score > 0.5) { // Confidence threshold
                                ctx.beginPath();
                                ctx.arc(x, y, 5, 0, 2 * Math.PI);
                                ctx.fillStyle = 'red';
                                ctx.fill();
                            }
                        });

                        // Draw skeleton connections
                        const skeleton = [
                            [5, 6], [5, 11], [6, 12], [11, 12], [5, 7], [7, 9], [6, 8], [8, 10],
                            [11, 13], [13, 15], [12, 14], [14, 16]
                        ];
                        skeleton.forEach(([start, end]) => {
                            const kp1 = pose.keypoints[start];
                            const kp2 = pose.keypoints[end];
                            if (kp1.score > 0.5 && kp2.score > 0.5) {
                                ctx.beginPath();
                                ctx.moveTo(kp1.x, kp1.y);
                                ctx.lineTo(kp2.x, kp2.y);
                                ctx.lineWidth = 2;
                                ctx.strokeStyle = 'blue';
                                ctx.stroke();
                            }
                        });
                    });
                } else {
                    if (lastFaceDetected) {
                        statusDiv.textContent = 'Лицо не обнаружено';
                        statusDiv.style.display = 'block';
                        lastFaceDetected = false;
                    }
                }

                requestAnimationFrame(detectPose);
            }

            detectPose();
        }

        async function main() {
            await setupCamera();
            video.play();
            loadModelAndDetect();
        }

        main();
    </script>
</body>
</html>
